{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from otterconnect.Environment import Connect4\n",
    "from otterconnect.Agent import RandomAgent, EPSGreedyQTable, EPSExpectedQTable\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c200abff",
   "metadata": {},
   "source": [
    "# Initialise Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b9186",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Connect4()\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c4a0e",
   "metadata": {},
   "source": [
    "# Initialise Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56624d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_1 = EPSGreedyQTable(num_actions=7, learning_rate=0.1)\n",
    "agent_2 = RandomAgent()\n",
    "agent_3 = EPSExpectedQTable(num_actions = 7, learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa02f97",
   "metadata": {},
   "source": [
    "# Example Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4860e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.reset()\n",
    "while not env.T:\n",
    "    action = agent_3.choose_test_action(env.current_state_)\n",
    "    env.step(action)\n",
    "    \n",
    "for state in env.states:\n",
    "    state.print_state()\n",
    "    \n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f8b7a4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19ff08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games = 10000\n",
    "\n",
    "for _ in tqdm(range(num_games)):\n",
    "    env.reset()\n",
    "    while not env.T:\n",
    "        action = agent_3.choose_train_action(env.current_state_)\n",
    "        env.step(action)\n",
    "    \n",
    "    states, actions, rewards = env.states, env.actions, env.rewards\n",
    "    \n",
    "    agent_3.update_table_with_game(states, actions,rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb76b5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
